# Week8
This week's work goal: to write the work part related to the paper.

## Partial record, see paper for details
Software Self Society: The Computer Histories of Adam Curtis article discusses how, the data processing systems of large corporations like Google and Facebook represent materialised manifestations of existing socio-political control structures. It emphasises that Silicon Valley is a site of political economy and carries a complex history and associated myths. Through archival images, Curtis demonstrates the reality of these data-processing machines, which are representative of the behind-the-scenes world of large tech corporations, including the viral dissemination of false and misleading information, which further erodes the subjectivity of our experiences and understandings of the past, present, and future.

This article also refers to images that, although they were not originally created with the internet in mind, have now become part of the web, similar to the function of the ancient Library of Alexandria - a vast repository of information. The 'Alexandrian quality' here refers to the network's ability to act as a storehouse of information, not only holding vast amounts of data, but also as a shared cultural memory, i.e. the Internet as a medium for storing and transmitting cultural heritage.

Artificial Intelligence-driven Generative Imaging utilises neural networks to learn synthesis rules from large image datasets. By taking image descriptions or random noise as input, AI generates one or more images for the user. Earlier approaches used GAN as a generative architecture. Some examples of GAN's generating works of art (e.g., photography, oil paintings, etc.) lead to the key question: what is the difference between humans and AIs in their perception of the authenticity of art-based images? How does this difference affect algorithms' and humans' judgements of image authenticity? Can humans find a reliable solution to distinguish whether an art image is AI-generated or not? How should humans adapt and act given that we cannot stop technological progress?

Most of the existing research on the perceptual differences between humans and AI focuses on the perceptual differences between real human faces, but I would like to start from the metfaces dataset to explore what are the differences between humans and AI on the perception of the authenticity of art images? As I am an art student myself, I would like to do this research using an interdisciplinary approach.

The paper by Zeyu Lu et al. establishes HPBench, a unique benchmark for comprehensively assessing human capabilities. In real-world scenarios, people use AI to generate images with the goal of creating high-quality images that are free of visual defects, as well as the user will choose the best image from multiple generated images. They have found that AI-generated images not only convey incorrect information to humans, but also erode their trust in accurate information. In addition, humans are better at recognising real photographs than fake ones, which can be attributed to their lifetime experience. Nonetheless, the difference between real image perception and AI-generated image perception was only 11.1 per cent, and they believe that future generative AI models could further reduce this gap. They also found that when it came to AI-generated images, participants with an AIGC background had a slightly improved ability to distinguish between the two categories. They also found that there may be significant differences categories in the way humans perceive different photographs, which also suggests that current AI-based generative models may be good at generating some categories but not so good at generating others.

Discuss previous research involving GANs:
In the proposed adversarial nets framework, the generative model is pitted against an adversary: a discriminative model that learns to determine In the proposed adversarial nets framework, the generative model is pitted against an adversary: a discriminative model that learns to determine whether a sample is from the model distribution or the data distribution. The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles. 
Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y. (2014). Generative Adversarial Networks.[online] arXiv.org. available at: https://arxiv.org/abs/1406.2661.

stylegan-fun:
Generative Adversarial Networks have long since revolutionised the world of computer vision and the world of art associated with it.
GANs have irreversibly changed the course of machine-assisted art. Some architectures are better suited to the alteration task.
While the discriminator must also improve its capabilities in order to train these larger networks, it is usually not explored, if not completely discarded.
Either it is used to generate an image it believes to be false (Amplifying The Uncanny), or it is used in conjunction with another classifier to update the weights of the generator.
In fact, the "false" or "true" images of the network itself do not translate into logical human visual features per se, but nonetheless, these features may still be aesthetically pleasing.
Diago provides a starting code on how to extract intermediate features for the StyleGAN2 discriminator
Amplifying The Uncanny:
The Role of the Discriminator: in traditional GANs, the discriminator is optimised to classify real data as real and generated data as fake, while the generator tries to trick the discriminator.
Fine-tuning GANs: The paper highlights the potential of discriminator networks in art creation. By freezing the weights of the discriminators and using them in conjunction with the generators, the paper explores novel outputs that are significantly different from images generated by typical GANs.
Reverse objective function: instead of optimising the generator to produce realistic images, the generator is fine-tuned to produce images that the discriminator classifies as false. This approach produces a range of artistic outputs that amplify the mysterious nature of machine-generated images. (Amplifying The Uncanny)

GAN:
The re-proposed adversarial network framework in which a generative model is pitted against an adversary: a discriminative model that learns to determine whether the samples are from a model distribution or from a climbing model. The generative model can be thought of as analogous to a group of counterfeiters trying to produce counterfeit money and use it without being detected, whereas the discriminative model is analogous to a police officer that is figure to detect counterfeit money. The discriminative model is also a multilayer perceptron.

The principle of StyleGAN3 leads to the reason why styleGAN3 was chosen (According to the researchers (Karras et al., 2021), current GAN designs do not create images naturally, despite The coarse features primarily determine the appearance of finer features, but not their specific placements. result, an alarming phenomenon is known as "texture clinging" can be seen in the minute details. StyleGAN3 may achieve a more natural transformation hierarchy because the precise sub-pixel location of each feature is only inherited from the coarse features.
Stylegan is famous for creating hyperrealistic quality images. It is increasingly used to generate art or any image with high resolution. Most of the images are faces or an animal.), the principle of the discriminator's judgement of image realism. 
